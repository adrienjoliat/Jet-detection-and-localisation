{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torch\n",
    "\n",
    "# Core Libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Operating System Interaction\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Machine Learning Frameworks\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# Model Building and Initialization\n",
    "import torch.nn as nn\n",
    "from torch.nn.init import kaiming_normal_\n",
    "\n",
    "# Data Loading and Dataset Handling\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split, Subset\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# Cross-Validation and Metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, roc_curve, auc, accuracy_score, confusion_matrix\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "# Visualization and Display\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from IPython.display import HTML\n",
    "from astropy.visualization import ImageNormalize, SqrtStretch\n",
    "import seaborn as sns\n",
    "import sunpy.visualization.colormaps as cm\n",
    "\n",
    "# Miscellaneous\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format of input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {\n",
    "    \"categories\": [ #id 1 will be changed from airplane to jet \n",
    "        {\"id\": 1, \"name\": \"airplane\", \"encode_name\": \"n02691156\"},\n",
    "        {\"id\": 2, \"name\": \"antelope\", \"encode_name\": \"n02419796\"},\n",
    "        {\"id\": 3, \"name\": \"bear\", \"encode_name\": \"n02131653\"},\n",
    "        {\"id\": 4, \"name\": \"bicycle\", \"encode_name\": \"n02834778\"},\n",
    "        {\"id\": 5, \"name\": \"bird\", \"encode_name\": \"n01503061\"},\n",
    "        {\"id\": 6, \"name\": \"bus\", \"encode_name\": \"n02924116\"},\n",
    "        {\"id\": 7, \"name\": \"car\", \"encode_name\": \"n02958343\"},\n",
    "        {\"id\": 8, \"name\": \"cattle\", \"encode_name\": \"n02402425\"},\n",
    "        {\"id\": 9, \"name\": \"dog\", \"encode_name\": \"n02084071\"},\n",
    "        {\"id\": 10, \"name\": \"domestic_cat\", \"encode_name\": \"n02121808\"},\n",
    "        {\"id\": 11, \"name\": \"elephant\", \"encode_name\": \"n02503517\"},\n",
    "        {\"id\": 12, \"name\": \"fox\", \"encode_name\": \"n02118333\"},\n",
    "        {\"id\": 13, \"name\": \"giant_panda\", \"encode_name\": \"n02510455\"},\n",
    "        {\"id\": 14, \"name\": \"hamster\", \"encode_name\": \"n02342885\"},\n",
    "        {\"id\": 15, \"name\": \"horse\", \"encode_name\": \"n02374451\"},\n",
    "        {\"id\": 16, \"name\": \"lion\", \"encode_name\": \"n02129165\"},\n",
    "        {\"id\": 17, \"name\": \"lizard\", \"encode_name\": \"n01674464\"},\n",
    "        {\"id\": 18, \"name\": \"monkey\", \"encode_name\": \"n02484322\"},\n",
    "        {\"id\": 19, \"name\": \"motorcycle\", \"encode_name\": \"n03790512\"},\n",
    "        {\"id\": 20, \"name\": \"rabbit\", \"encode_name\": \"n02324045\"},\n",
    "        {\"id\": 21, \"name\": \"red_panda\", \"encode_name\": \"n02509815\"},\n",
    "        {\"id\": 22, \"name\": \"sheep\", \"encode_name\": \"n02411705\"},\n",
    "        {\"id\": 23, \"name\": \"snake\", \"encode_name\": \"n01726692\"},\n",
    "        {\"id\": 24, \"name\": \"squirrel\", \"encode_name\": \"n02355227\"},\n",
    "        {\"id\": 25, \"name\": \"tiger\", \"encode_name\": \"n02129604\"},\n",
    "        {\"id\": 26, \"name\": \"train\", \"encode_name\": \"n04468005\"},\n",
    "        {\"id\": 27, \"name\": \"turtle\", \"encode_name\": \"n01662784\"},\n",
    "        {\"id\": 28, \"name\": \"watercraft\", \"encode_name\": \"n04530566\"},\n",
    "        {\"id\": 29, \"name\": \"whale\", \"encode_name\": \"n02062744\"},\n",
    "        {\"id\": 30, \"name\": \"zebra\", \"encode_name\": \"n02391049\"}\n",
    "    ],\n",
    "\n",
    "    \"images\":[\n",
    "        {\"file_name\" : \"DET/train/ILSVRC2014_train_0000/ILSVRC2014_train_00000663.JPEG\", \n",
    "         \"height\": 166, \n",
    "         \"width\": 166, \n",
    "         \"id\": 1, #starting from 1\n",
    "         \"frame_id\": -1,  #starting from 0 and reseting when changing video\n",
    "         \"video_id\": 1, \n",
    "         \"is_vid_train_frame\": True}\n",
    "    ],#all files (images)\n",
    "\n",
    "    \"annotations\" :[\n",
    "        {\"id\": 1, #one id per image even if it's in the same vid\n",
    "         \"video_id\": 1, #goes up to the number of videos \n",
    "         \"image_id\": 1, \n",
    "         \"category_id\": 1, #will always be 1 as the jets will be classified as 1 \n",
    "         \"instance_id\": 1, \n",
    "         \"bbox\": [1, 90, 496, 271], \n",
    "         \"area\": 134416, \n",
    "         \"iscrowd\": False, \n",
    "         \"occluded\": False, \n",
    "         \"generated\": False}\n",
    "    ],\n",
    "\n",
    "    \"videos\":[\n",
    "        {\"id\": 1,\n",
    "        \"name\": \"VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00000000\", \n",
    "        \"vid_train_frames\": [9, 29, 49, 69, 89, 109, 129, 149, 169, 189, 209, 229, 249, 269, 289]} #take all frames maybe for training\n",
    "    ]   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take all labeled events and transform them into JET_train_eventx/imagex.JPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000_000.csv', '000_001.csv', '000_002.csv', '000_003.csv', '000_004.csv', '000_005.csv', '000_006.csv', '000_007.csv', '000_008.csv', '000_009.csv', '000_010.csv', '000_011.csv', '000_012.csv', '000_013.csv', '000_014.csv', '000_015.csv', '000_016.csv', '000_017.csv', '000_018.csv', '000_019.csv', '000_020.csv', '000_021.csv', '000_022.csv', '000_023.csv', '000_024.csv', '000_025.csv', '000_026.csv', '000_027.csv', '000_028.csv', '000_029.csv', '000_030.csv', '000_031.csv', '000_032.csv', '000_033.csv', '000_034.csv', '000_035.csv', '000_036.csv', '000_037.csv', '000_038.csv', '000_039.csv', '000_040.csv', '000_041.csv', '000_042.csv', '000_043.csv', '000_044.csv', '000_045.csv', '000_046.csv', '000_047.csv', '000_048.csv', '000_049.csv', '000_050.csv', '000_051.csv', '000_052.csv', '000_053.csv', '000_054.csv', '000_055.csv', '000_056.csv', '000_057.csv', '000_058.csv', '000_059.csv', '000_060.csv', '000_061.csv', '000_062.csv', '000_063.csv', '000_064.csv', '000_065.csv', '000_066.csv', '000_067.csv', '000_068.csv', '000_069.csv', '000_070.csv', '000_071.csv', '000_072.csv', '000_073.csv', '000_074.csv', '000_075.csv', '000_076.csv', '000_077.csv', '000_078.csv', '000_079.csv', '000_080.csv', '000_081.csv', '000_082.csv', '000_083.csv', '000_084.csv', '000_085.csv', '000_086.csv', '000_087.csv', '000_088.csv', '000_089.csv', '000_090.csv', '000_091.csv', '000_092.csv', '000_093.csv', '000_094.csv', '000_095.csv', '000_096.csv', '000_097.csv', '000_098.csv', '000_099.csv', '000_100.csv', '000_101.csv', '000_102.csv', '000_103.csv', '000_104.csv', '000_105.csv', '000_106.csv', '000_107.csv', '000_108.csv', '000_109.csv']\n",
      "110\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_files_in_folder(folder_path):\n",
    "    \"\"\"\n",
    "    List all files in a folder in ascending order.\n",
    "    \n",
    "    Args:\n",
    "    - folder_path: The path to the folder\n",
    "    \n",
    "    Returns:\n",
    "    - file_names: A list of file names in the folder, sorted in ascending order\n",
    "    \"\"\"\n",
    "    file_names = []\n",
    "    for file_name in sorted(os.listdir(folder_path), key=lambda x: int(os.path.splitext(x)[0])):\n",
    "        if os.path.isfile(os.path.join(folder_path, file_name)):\n",
    "            file_names.append(file_name)\n",
    "    return file_names\n",
    "\n",
    "# Example usage:\n",
    "folder_path = \"../../../../jet_box_sophie/bbox_events_jets/000\"\n",
    "file_names = list_files_in_folder(folder_path)\n",
    "print(file_names)\n",
    "print(len(file_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_data(folder_path,data):\n",
    "\n",
    "    video_id = len(data[\"videos\"]) + 1 #everytime we change folder video id is increased by one\n",
    "    vid_info = {\n",
    "                \"id\": video_id,\n",
    "                \"name\":folder_path[-13:].replace(\"\\\\\", \"/\"),\n",
    "                \"vid_train_frames\":[i for i in range(len(os.listdir(folder_path)))]\n",
    "            }\n",
    "\n",
    "    data[\"videos\"].append(vid_info)\n",
    "\n",
    "    frame_id=0\n",
    "\n",
    "    \n",
    "    #print(folder_path)\n",
    "    for i, filename in enumerate(os.listdir(folder_path)):\n",
    "        #print(filename)\n",
    "        #IMAGE INFOS\n",
    "        if filename.endswith(\".JPEG\"):\n",
    "            image_id = len(data[\"images\"]) + 1\n",
    "            annot_id = len(data[\"annotations\"]) + 1\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            if i ==0:\n",
    "                with Image.open(image_path) as img:\n",
    "                    width, height = img.size\n",
    "            \n",
    "\n",
    "            image_info = {\n",
    "                \"file_name\": os.path.relpath(image_path[7:],\".\").replace(\"\\\\\", \"/\"),\n",
    "                \"height\": height,\n",
    "                \"width\": width,\n",
    "                \"id\": image_id,\n",
    "                \"frame_id\": frame_id,\n",
    "                \"video_id\": video_id,\n",
    "                \"is_vid_train_frame\": True\n",
    "            }\n",
    "            data[\"images\"].append(image_info)\n",
    "\n",
    "\n",
    "        #BOUNDING BOX INFOS (ANNOTATIONS)\n",
    "            bbox_im=pd.read_csv(f\"./Data/bbox_events_jets/{filename[:3]}/{filename[:3]}_{filename[4:7]}.csv\").values.tolist()\n",
    "           \n",
    "            for bbox in bbox_im: #If multiple bbox for one image\n",
    "                bbox_area=torch.tensor(bbox).view(1,4)\n",
    "                area=torchvision.ops.box_area(bbox_area).item()\n",
    "                width = bbox[2] - bbox[0]\n",
    "                height = bbox[3] - bbox[1]\n",
    "                # Create a list containing [x_min, y_min, width, height]\n",
    "                bbox_list = [bbox[0], bbox[1], width, height]\n",
    "                #print(bbox_list)\n",
    "                annotation_info = {\n",
    "                    \"id\": annot_id,\n",
    "                    \"video_id\": video_id,\n",
    "                    \"image_id\": image_id,\n",
    "                    \"category_id\": 1,\n",
    "                    \"instance_id\": 1,\n",
    "                    \"bbox\": bbox_list, #in [x1,y1,x2,y2]                              \n",
    "                    \"area\": area, \n",
    "                    \"iscrowd\": False,\n",
    "                    \"occluded\": False,\n",
    "                    \"generated\": False\n",
    "                }\n",
    "                data[\"annotations\"].append(annotation_info)\n",
    "                annot_id+=1\n",
    "            frame_id+=1\n",
    "            \n",
    "    return data\n",
    "# Function to generate data for each folder in a directory\n",
    "def generate_folder_data(root_folder, data):\n",
    "    for folder_name in os.listdir(root_folder):#All folder in folder path (VID) TRAIN or VAL\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            data=generate_image_data(folder_path,data)\n",
    "\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"categories\": [ #id 1 will be changed from airplane to jet \n",
    "        {\"id\": 1, \"name\": \"jet\", \"encode_name\": \"n02691156\"},\n",
    "        {\"id\": 2, \"name\": \"antelope\", \"encode_name\": \"n02419796\"},\n",
    "        {\"id\": 3, \"name\": \"bear\", \"encode_name\": \"n02131653\"},\n",
    "        {\"id\": 4, \"name\": \"bicycle\", \"encode_name\": \"n02834778\"},\n",
    "        {\"id\": 5, \"name\": \"bird\", \"encode_name\": \"n01503061\"},\n",
    "        {\"id\": 6, \"name\": \"bus\", \"encode_name\": \"n02924116\"},\n",
    "        {\"id\": 7, \"name\": \"car\", \"encode_name\": \"n02958343\"},\n",
    "        {\"id\": 8, \"name\": \"cattle\", \"encode_name\": \"n02402425\"},\n",
    "        {\"id\": 9, \"name\": \"dog\", \"encode_name\": \"n02084071\"},\n",
    "        {\"id\": 10, \"name\": \"domestic_cat\", \"encode_name\": \"n02121808\"},\n",
    "        {\"id\": 11, \"name\": \"elephant\", \"encode_name\": \"n02503517\"},\n",
    "        {\"id\": 12, \"name\": \"fox\", \"encode_name\": \"n02118333\"},\n",
    "        {\"id\": 13, \"name\": \"giant_panda\", \"encode_name\": \"n02510455\"},\n",
    "        {\"id\": 14, \"name\": \"hamster\", \"encode_name\": \"n02342885\"},\n",
    "        {\"id\": 15, \"name\": \"horse\", \"encode_name\": \"n02374451\"},\n",
    "        {\"id\": 16, \"name\": \"lion\", \"encode_name\": \"n02129165\"},\n",
    "        {\"id\": 17, \"name\": \"lizard\", \"encode_name\": \"n01674464\"},\n",
    "        {\"id\": 18, \"name\": \"monkey\", \"encode_name\": \"n02484322\"},\n",
    "        {\"id\": 19, \"name\": \"motorcycle\", \"encode_name\": \"n03790512\"},\n",
    "        {\"id\": 20, \"name\": \"rabbit\", \"encode_name\": \"n02324045\"},\n",
    "        {\"id\": 21, \"name\": \"red_panda\", \"encode_name\": \"n02509815\"},\n",
    "        {\"id\": 22, \"name\": \"sheep\", \"encode_name\": \"n02411705\"},\n",
    "        {\"id\": 23, \"name\": \"snake\", \"encode_name\": \"n01726692\"},\n",
    "        {\"id\": 24, \"name\": \"squirrel\", \"encode_name\": \"n02355227\"},\n",
    "        {\"id\": 25, \"name\": \"tiger\", \"encode_name\": \"n02129604\"},\n",
    "        {\"id\": 26, \"name\": \"train\", \"encode_name\": \"n04468005\"},\n",
    "        {\"id\": 27, \"name\": \"turtle\", \"encode_name\": \"n01662784\"},\n",
    "        {\"id\": 28, \"name\": \"watercraft\", \"encode_name\": \"n04530566\"},\n",
    "        {\"id\": 29, \"name\": \"whale\", \"encode_name\": \"n02062744\"},\n",
    "        {\"id\": 30, \"name\": \"zebra\", \"encode_name\": \"n02391049\"}\n",
    "    ],\n",
    "\n",
    "    \"images\":[\n",
    "    ],#all files (images)\n",
    "\n",
    "    \"annotations\" :[\n",
    "    ],\n",
    "\n",
    "    \"videos\":[\n",
    "    ]   \n",
    "}\n",
    "\n",
    "# Generating data for each folder in the big folder\n",
    "big_folder_path = \"./Data/VID/TRAIN\"\n",
    "generate_folder_data(big_folder_path, data)\n",
    "\n",
    "def print_tensor_keys(data):\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(\"Key:\", key)\n",
    "            print(\"Value (Tensor):\", value)\n",
    "\n",
    "# Add this function call before serializing to JSON\n",
    "print_tensor_keys(data)\n",
    "# Saving the modified data to a JSON file\n",
    "with open(\"./annotations/imagenet_vid_train_joint_30.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28764\n",
      "28764\n"
     ]
    }
   ],
   "source": [
    "print(len(data[\"images\"]))\n",
    "print(len(data[\"annotations\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_data(folder_path,data):\n",
    "\n",
    "    video_id = len(data[\"videos\"]) + 1 #everytime we change folder video id is increased by one\n",
    "    vid_info = {\n",
    "                \"id\": video_id,\n",
    "                \"name\":folder_path[-7:].replace(\"\\\\\", \"/\"),\n",
    "                \"vid_train_frames\":[]\n",
    "            }\n",
    "\n",
    "    data[\"videos\"].append(vid_info)\n",
    "\n",
    "    frame_id=0\n",
    "\n",
    "    \n",
    "    #print(folder_path)\n",
    "    for i, filename in enumerate(os.listdir(folder_path)):\n",
    "        #print(filename)\n",
    "        #IMAGE INFOS\n",
    "        if filename.endswith(\".JPEG\"):\n",
    "            image_id = len(data[\"images\"]) + 1\n",
    "            annot_id = len(data[\"annotations\"]) + 1\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            if i ==0:\n",
    "                with Image.open(image_path) as img:\n",
    "                    width, height = img.size\n",
    "            \n",
    "\n",
    "            image_info = {\n",
    "                \"file_name\": image_path[11:].replace(\"\\\\\", \"/\"),\n",
    "                \"height\": height,\n",
    "                \"width\": width,\n",
    "                \"id\": image_id,\n",
    "                \"frame_id\": frame_id,\n",
    "                \"video_id\": video_id,\n",
    "                \"is_vid_train_frame\": False\n",
    "            }\n",
    "            data[\"images\"].append(image_info)\n",
    "\n",
    "\n",
    "        #BOUNDING BOX INFOS (ANNOTATIONS)\n",
    "            bbox_im=pd.read_csv(f\"./Data/bbox_events_jets/{filename[:3]}/{filename[:3]}_{filename[4:7]}.csv\").values.tolist()\n",
    "           \n",
    "            for bbox in bbox_im: #If multiple bbox for one image\n",
    "                bbox_area=torch.tensor(bbox).view(1,4)\n",
    "                area=torchvision.ops.box_area(bbox_area).item()\n",
    "                width = bbox[2] - bbox[0]\n",
    "                height = bbox[3] - bbox[1]\n",
    "                # Create a list containing [x_min, y_min, width, height]\n",
    "                bbox_list = [bbox[0], bbox[1], width, height]\n",
    "                annotation_info = {\n",
    "                    \"id\": annot_id,\n",
    "                    \"video_id\": video_id,\n",
    "                    \"image_id\": image_id,\n",
    "                    \"category_id\": 1,\n",
    "                    \"instance_id\": 1,\n",
    "                    \"bbox\": bbox_list, #in [x1,y1,w,h]                              \n",
    "                    \"area\": area, \n",
    "                    \"iscrowd\": False,\n",
    "                    \"occluded\": False,\n",
    "                    \"generated\": False\n",
    "                }\n",
    "                data[\"annotations\"].append(annotation_info)\n",
    "                annot_id+=1\n",
    "            frame_id+=1\n",
    "            \n",
    "    return data\n",
    "# Function to generate data for each folder in a directory\n",
    "def generate_folder_data(root_folder, data):\n",
    "    for folder_name in os.listdir(root_folder):#All folder in folder path (VID) TRAIN or VAL\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            data=generate_image_data(folder_path,data)\n",
    "\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"categories\": [ #id 1 will be changed from airplane to jet \n",
    "        {\"id\": 1, \"name\": \"jet\", \"encode_name\": \"n02691156\"},\n",
    "        {\"id\": 2, \"name\": \"antelope\", \"encode_name\": \"n02419796\"},\n",
    "        {\"id\": 3, \"name\": \"bear\", \"encode_name\": \"n02131653\"},\n",
    "        {\"id\": 4, \"name\": \"bicycle\", \"encode_name\": \"n02834778\"},\n",
    "        {\"id\": 5, \"name\": \"bird\", \"encode_name\": \"n01503061\"},\n",
    "        {\"id\": 6, \"name\": \"bus\", \"encode_name\": \"n02924116\"},\n",
    "        {\"id\": 7, \"name\": \"car\", \"encode_name\": \"n02958343\"},\n",
    "        {\"id\": 8, \"name\": \"cattle\", \"encode_name\": \"n02402425\"},\n",
    "        {\"id\": 9, \"name\": \"dog\", \"encode_name\": \"n02084071\"},\n",
    "        {\"id\": 10, \"name\": \"domestic_cat\", \"encode_name\": \"n02121808\"},\n",
    "        {\"id\": 11, \"name\": \"elephant\", \"encode_name\": \"n02503517\"},\n",
    "        {\"id\": 12, \"name\": \"fox\", \"encode_name\": \"n02118333\"},\n",
    "        {\"id\": 13, \"name\": \"giant_panda\", \"encode_name\": \"n02510455\"},\n",
    "        {\"id\": 14, \"name\": \"hamster\", \"encode_name\": \"n02342885\"},\n",
    "        {\"id\": 15, \"name\": \"horse\", \"encode_name\": \"n02374451\"},\n",
    "        {\"id\": 16, \"name\": \"lion\", \"encode_name\": \"n02129165\"},\n",
    "        {\"id\": 17, \"name\": \"lizard\", \"encode_name\": \"n01674464\"},\n",
    "        {\"id\": 18, \"name\": \"monkey\", \"encode_name\": \"n02484322\"},\n",
    "        {\"id\": 19, \"name\": \"motorcycle\", \"encode_name\": \"n03790512\"},\n",
    "        {\"id\": 20, \"name\": \"rabbit\", \"encode_name\": \"n02324045\"},\n",
    "        {\"id\": 21, \"name\": \"red_panda\", \"encode_name\": \"n02509815\"},\n",
    "        {\"id\": 22, \"name\": \"sheep\", \"encode_name\": \"n02411705\"},\n",
    "        {\"id\": 23, \"name\": \"snake\", \"encode_name\": \"n01726692\"},\n",
    "        {\"id\": 24, \"name\": \"squirrel\", \"encode_name\": \"n02355227\"},\n",
    "        {\"id\": 25, \"name\": \"tiger\", \"encode_name\": \"n02129604\"},\n",
    "        {\"id\": 26, \"name\": \"train\", \"encode_name\": \"n04468005\"},\n",
    "        {\"id\": 27, \"name\": \"turtle\", \"encode_name\": \"n01662784\"},\n",
    "        {\"id\": 28, \"name\": \"watercraft\", \"encode_name\": \"n04530566\"},\n",
    "        {\"id\": 29, \"name\": \"whale\", \"encode_name\": \"n02062744\"},\n",
    "        {\"id\": 30, \"name\": \"zebra\", \"encode_name\": \"n02391049\"}\n",
    "    ],\n",
    "\n",
    "    \"images\":[\n",
    "    ],#all files (images)\n",
    "\n",
    "    \"annotations\" :[\n",
    "    ],\n",
    "\n",
    "    \"videos\":[\n",
    "    ]   \n",
    "}\n",
    "\n",
    "# Generating data for each folder in the big folder\n",
    "big_folder_path = \"./Data/VID/VAL\"\n",
    "generate_folder_data(big_folder_path, data)\n",
    "\n",
    "# Saving the modified data to a JSON file\n",
    "with open(\"./annotations/imagenet_vid_val.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3288\n",
      "3288\n"
     ]
    }
   ],
   "source": [
    "print(len(data[\"images\"]))\n",
    "print(len(data[\"annotations\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating mean and std of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently :0 %\n",
      "Currently :0 %\n",
      "Currently :0 %\n",
      "Currently :0 %\n",
      "Currently :0 %\n",
      "Currently :0 %\n",
      "Currently :0 %\n",
      "Currently :0 %\n",
      "Currently :1 %\n",
      "Currently :1 %\n",
      "Currently :1 %\n",
      "Currently :1 %\n",
      "Currently :2 %\n",
      "Currently :2 %\n",
      "Currently :2 %\n",
      "Currently :2 %\n",
      "Currently :2 %\n",
      "Currently :2 %\n",
      "Currently :3 %\n",
      "Currently :3 %\n",
      "Currently :3 %\n",
      "Currently :3 %\n",
      "Currently :3 %\n",
      "Currently :3 %\n",
      "Currently :3 %\n",
      "Currently :3 %\n",
      "Currently :4 %\n",
      "Currently :4 %\n",
      "Currently :4 %\n",
      "Currently :4 %\n",
      "Currently :4 %\n",
      "Currently :4 %\n",
      "Currently :4 %\n",
      "Currently :4 %\n",
      "Currently :5 %\n",
      "Currently :5 %\n",
      "Currently :5 %\n",
      "Currently :5 %\n",
      "Currently :5 %\n",
      "Currently :5 %\n",
      "Currently :5 %\n",
      "Currently :6 %\n",
      "Currently :6 %\n",
      "Currently :6 %\n",
      "Currently :6 %\n",
      "Currently :6 %\n",
      "Currently :6 %\n",
      "Currently :6 %\n",
      "Currently :6 %\n",
      "Currently :6 %\n",
      "Currently :6 %\n",
      "Currently :6 %\n",
      "Currently :6 %\n",
      "Currently :7 %\n",
      "Currently :7 %\n",
      "Currently :7 %\n",
      "Currently :7 %\n",
      "Currently :7 %\n",
      "Currently :7 %\n",
      "Currently :7 %\n",
      "Currently :8 %\n",
      "Currently :8 %\n",
      "Currently :8 %\n",
      "Currently :8 %\n",
      "Currently :8 %\n",
      "Currently :8 %\n",
      "Currently :8 %\n",
      "Currently :9 %\n",
      "Currently :9 %\n",
      "Currently :9 %\n",
      "Currently :9 %\n",
      "Currently :9 %\n",
      "Currently :9 %\n",
      "Currently :10 %\n",
      "Currently :10 %\n",
      "Currently :10 %\n",
      "Currently :10 %\n",
      "Currently :10 %\n",
      "Currently :10 %\n",
      "Currently :10 %\n",
      "Currently :11 %\n",
      "Currently :11 %\n",
      "Currently :11 %\n",
      "Currently :11 %\n",
      "Currently :11 %\n",
      "Currently :11 %\n",
      "Currently :11 %\n",
      "Currently :12 %\n",
      "Currently :12 %\n",
      "Currently :12 %\n",
      "Currently :12 %\n",
      "Currently :12 %\n",
      "Currently :12 %\n",
      "Currently :12 %\n",
      "Currently :12 %\n",
      "Currently :12 %\n",
      "Currently :12 %\n",
      "Currently :13 %\n",
      "Currently :13 %\n",
      "Currently :13 %\n",
      "Currently :13 %\n",
      "Currently :13 %\n",
      "Currently :13 %\n",
      "Currently :14 %\n",
      "Currently :14 %\n",
      "Currently :14 %\n",
      "Currently :14 %\n",
      "Currently :14 %\n",
      "Currently :14 %\n",
      "Currently :14 %\n",
      "Currently :14 %\n",
      "Currently :14 %\n",
      "Currently :14 %\n",
      "Currently :14 %\n",
      "Currently :15 %\n",
      "Currently :15 %\n",
      "Currently :15 %\n",
      "Currently :15 %\n",
      "Currently :15 %\n",
      "Currently :15 %\n",
      "Currently :16 %\n",
      "Currently :16 %\n",
      "Currently :16 %\n",
      "Currently :16 %\n",
      "Currently :16 %\n",
      "Currently :16 %\n",
      "Currently :16 %\n",
      "Currently :16 %\n",
      "Currently :16 %\n",
      "Currently :16 %\n",
      "Currently :17 %\n",
      "Currently :17 %\n",
      "Currently :17 %\n",
      "Currently :17 %\n",
      "Currently :17 %\n",
      "Currently :18 %\n",
      "Currently :18 %\n",
      "Currently :18 %\n",
      "Currently :18 %\n",
      "Currently :19 %\n",
      "Currently :19 %\n",
      "Currently :19 %\n",
      "Currently :19 %\n",
      "Currently :20 %\n",
      "Currently :20 %\n",
      "Currently :20 %\n",
      "Currently :20 %\n",
      "Currently :20 %\n",
      "Currently :20 %\n",
      "Currently :20 %\n",
      "Currently :21 %\n",
      "Currently :21 %\n",
      "Currently :21 %\n",
      "Currently :21 %\n",
      "Currently :21 %\n",
      "Currently :21 %\n",
      "Currently :21 %\n",
      "Currently :21 %\n",
      "Currently :21 %\n",
      "Currently :21 %\n",
      "Currently :21 %\n",
      "Currently :22 %\n",
      "Currently :22 %\n",
      "Currently :22 %\n",
      "Currently :22 %\n",
      "Currently :22 %\n",
      "Currently :22 %\n",
      "Currently :22 %\n",
      "Currently :23 %\n",
      "Currently :23 %\n",
      "Currently :23 %\n",
      "Currently :23 %\n",
      "Currently :23 %\n",
      "Currently :23 %\n",
      "Currently :23 %\n",
      "Currently :23 %\n",
      "Currently :24 %\n",
      "Currently :24 %\n",
      "Currently :24 %\n",
      "Currently :24 %\n",
      "Currently :24 %\n",
      "Currently :25 %\n",
      "Currently :25 %\n",
      "Currently :25 %\n",
      "Currently :25 %\n",
      "Currently :25 %\n",
      "Currently :25 %\n",
      "Currently :25 %\n",
      "Currently :26 %\n",
      "Currently :26 %\n",
      "Currently :26 %\n",
      "Currently :26 %\n",
      "Currently :26 %\n",
      "Currently :26 %\n",
      "Currently :26 %\n",
      "Currently :27 %\n",
      "Currently :27 %\n",
      "Currently :27 %\n",
      "Currently :27 %\n",
      "Currently :28 %\n",
      "Currently :28 %\n",
      "Currently :28 %\n",
      "Currently :28 %\n",
      "Currently :28 %\n",
      "Currently :29 %\n",
      "Currently :29 %\n",
      "Currently :29 %\n",
      "Currently :29 %\n",
      "Currently :29 %\n",
      "Currently :29 %\n",
      "Currently :30 %\n",
      "Currently :30 %\n",
      "Currently :30 %\n",
      "Currently :30 %\n",
      "Currently :30 %\n",
      "Currently :30 %\n",
      "Currently :30 %\n",
      "Currently :30 %\n",
      "Currently :31 %\n",
      "Currently :31 %\n",
      "Currently :31 %\n",
      "Currently :31 %\n",
      "Currently :32 %\n",
      "Currently :32 %\n",
      "Currently :32 %\n",
      "Currently :32 %\n",
      "Currently :32 %\n",
      "Currently :32 %\n",
      "Currently :32 %\n",
      "Currently :33 %\n",
      "Currently :33 %\n",
      "Currently :33 %\n",
      "Currently :33 %\n",
      "Currently :33 %\n",
      "Currently :33 %\n",
      "Currently :33 %\n",
      "Currently :34 %\n",
      "Currently :34 %\n",
      "Currently :34 %\n",
      "Currently :34 %\n",
      "Currently :34 %\n",
      "Currently :34 %\n",
      "Currently :35 %\n",
      "Currently :35 %\n",
      "Currently :35 %\n",
      "Currently :35 %\n",
      "Currently :35 %\n",
      "Currently :35 %\n",
      "Currently :35 %\n",
      "Currently :36 %\n",
      "Currently :36 %\n",
      "Currently :36 %\n",
      "Currently :36 %\n",
      "Currently :36 %\n",
      "Currently :36 %\n",
      "Currently :37 %\n",
      "Currently :37 %\n",
      "Currently :37 %\n",
      "Currently :37 %\n",
      "Currently :37 %\n",
      "Currently :37 %\n",
      "Currently :37 %\n",
      "Currently :37 %\n",
      "Currently :38 %\n",
      "Currently :38 %\n",
      "Currently :38 %\n",
      "Currently :38 %\n",
      "Currently :38 %\n",
      "Currently :38 %\n",
      "Currently :38 %\n",
      "Currently :38 %\n",
      "Currently :38 %\n",
      "Currently :38 %\n",
      "Currently :39 %\n",
      "Currently :39 %\n",
      "Currently :39 %\n",
      "Currently :39 %\n",
      "Currently :39 %\n",
      "Currently :40 %\n",
      "Currently :40 %\n",
      "Currently :40 %\n",
      "Currently :40 %\n",
      "Currently :40 %\n",
      "Currently :40 %\n",
      "Currently :40 %\n",
      "Currently :40 %\n",
      "Currently :40 %\n",
      "Currently :41 %\n",
      "Currently :41 %\n",
      "Currently :41 %\n",
      "Currently :41 %\n",
      "Currently :42 %\n",
      "Currently :42 %\n",
      "Currently :42 %\n",
      "Currently :43 %\n",
      "Currently :43 %\n",
      "Currently :43 %\n",
      "Currently :43 %\n",
      "Currently :43 %\n",
      "Currently :43 %\n",
      "Currently :43 %\n",
      "Currently :44 %\n",
      "Currently :44 %\n",
      "Currently :44 %\n",
      "Currently :45 %\n",
      "Currently :45 %\n",
      "Currently :45 %\n",
      "Currently :45 %\n",
      "Currently :45 %\n",
      "Currently :45 %\n",
      "Currently :45 %\n",
      "Currently :45 %\n",
      "Currently :45 %\n",
      "Currently :45 %\n",
      "Currently :45 %\n",
      "Currently :45 %\n",
      "Currently :46 %\n",
      "Currently :46 %\n",
      "Currently :46 %\n",
      "Currently :46 %\n",
      "Currently :46 %\n",
      "Currently :46 %\n",
      "Currently :47 %\n",
      "Currently :47 %\n",
      "Currently :47 %\n",
      "Currently :47 %\n",
      "Currently :47 %\n",
      "Currently :48 %\n",
      "Currently :48 %\n",
      "Currently :48 %\n",
      "Currently :48 %\n",
      "Currently :48 %\n",
      "Currently :49 %\n",
      "Currently :49 %\n",
      "Currently :49 %\n",
      "Currently :49 %\n",
      "Currently :49 %\n",
      "Currently :49 %\n",
      "Currently :49 %\n",
      "Currently :49 %\n",
      "Currently :50 %\n",
      "Currently :50 %\n",
      "Currently :50 %\n",
      "Currently :50 %\n",
      "Currently :51 %\n",
      "Currently :51 %\n",
      "Currently :51 %\n",
      "Currently :51 %\n",
      "Currently :51 %\n",
      "Currently :52 %\n",
      "Currently :52 %\n",
      "Currently :52 %\n",
      "Currently :52 %\n",
      "Currently :52 %\n",
      "Currently :53 %\n",
      "Currently :53 %\n",
      "Currently :53 %\n",
      "Currently :53 %\n",
      "Currently :53 %\n",
      "Currently :53 %\n",
      "Currently :53 %\n",
      "Currently :54 %\n",
      "Currently :54 %\n",
      "Currently :54 %\n",
      "Currently :54 %\n",
      "Currently :54 %\n",
      "Currently :54 %\n",
      "Currently :54 %\n",
      "Currently :55 %\n",
      "Currently :55 %\n",
      "Currently :55 %\n",
      "Currently :55 %\n",
      "Currently :55 %\n",
      "Currently :55 %\n",
      "Currently :55 %\n",
      "Currently :55 %\n",
      "Currently :56 %\n",
      "Currently :56 %\n",
      "Currently :56 %\n",
      "Currently :56 %\n",
      "Currently :56 %\n",
      "Currently :56 %\n",
      "Currently :56 %\n",
      "Currently :56 %\n",
      "Currently :56 %\n",
      "Currently :57 %\n",
      "Currently :57 %\n",
      "Currently :57 %\n",
      "Currently :57 %\n",
      "Currently :57 %\n",
      "Currently :57 %\n",
      "Currently :57 %\n",
      "Currently :57 %\n",
      "Currently :57 %\n",
      "Currently :57 %\n",
      "Currently :58 %\n",
      "Currently :58 %\n",
      "Currently :58 %\n",
      "Currently :58 %\n",
      "Currently :58 %\n",
      "Currently :58 %\n",
      "Currently :58 %\n",
      "Currently :58 %\n",
      "Currently :58 %\n",
      "Currently :59 %\n",
      "Currently :59 %\n",
      "Currently :59 %\n",
      "Currently :59 %\n",
      "Currently :59 %\n",
      "Currently :59 %\n",
      "Currently :59 %\n",
      "Currently :59 %\n",
      "Currently :59 %\n",
      "Currently :60 %\n",
      "Currently :60 %\n",
      "Currently :60 %\n",
      "Currently :60 %\n",
      "Currently :60 %\n",
      "Currently :60 %\n",
      "Currently :60 %\n",
      "Currently :60 %\n",
      "Currently :60 %\n",
      "Currently :61 %\n",
      "Currently :61 %\n",
      "Currently :61 %\n",
      "Currently :61 %\n",
      "Currently :61 %\n",
      "Currently :61 %\n",
      "Currently :61 %\n",
      "Currently :61 %\n",
      "Currently :61 %\n",
      "Currently :62 %\n",
      "Currently :62 %\n",
      "Currently :62 %\n",
      "Currently :62 %\n",
      "Currently :62 %\n",
      "Currently :62 %\n",
      "Currently :62 %\n",
      "Currently :62 %\n",
      "Currently :62 %\n",
      "Currently :63 %\n",
      "Currently :63 %\n",
      "Currently :63 %\n",
      "Currently :63 %\n",
      "Currently :63 %\n",
      "Currently :63 %\n",
      "Currently :63 %\n",
      "Currently :64 %\n",
      "Currently :64 %\n",
      "Currently :64 %\n",
      "Currently :64 %\n",
      "Currently :64 %\n",
      "Currently :64 %\n",
      "Currently :64 %\n",
      "Currently :65 %\n",
      "Currently :65 %\n",
      "Currently :65 %\n",
      "Currently :65 %\n",
      "Currently :65 %\n",
      "Currently :65 %\n",
      "Currently :66 %\n",
      "Currently :66 %\n",
      "Currently :66 %\n",
      "Currently :66 %\n",
      "Currently :66 %\n",
      "Currently :67 %\n",
      "Currently :67 %\n",
      "Currently :67 %\n",
      "Currently :67 %\n",
      "Currently :67 %\n",
      "Currently :67 %\n",
      "Currently :68 %\n",
      "Currently :68 %\n",
      "Currently :68 %\n",
      "Currently :68 %\n",
      "Currently :68 %\n",
      "Currently :68 %\n",
      "Currently :68 %\n",
      "Currently :68 %\n",
      "Currently :69 %\n",
      "Currently :69 %\n",
      "Currently :69 %\n",
      "Currently :69 %\n",
      "Currently :69 %\n",
      "Currently :69 %\n",
      "Currently :69 %\n",
      "Currently :69 %\n",
      "Currently :70 %\n",
      "Currently :70 %\n",
      "Currently :70 %\n",
      "Currently :70 %\n",
      "Currently :70 %\n",
      "Currently :71 %\n",
      "Currently :71 %\n",
      "Currently :71 %\n",
      "Currently :71 %\n",
      "Currently :71 %\n",
      "Currently :71 %\n",
      "Currently :71 %\n",
      "Currently :71 %\n",
      "Currently :71 %\n",
      "Currently :72 %\n",
      "Currently :72 %\n",
      "Currently :72 %\n",
      "Currently :72 %\n",
      "Currently :72 %\n",
      "Currently :72 %\n",
      "Currently :72 %\n",
      "Currently :73 %\n",
      "Currently :73 %\n",
      "Currently :73 %\n",
      "Currently :73 %\n",
      "Currently :73 %\n",
      "Currently :73 %\n",
      "Currently :74 %\n",
      "Currently :74 %\n",
      "Currently :74 %\n",
      "Currently :74 %\n",
      "Currently :74 %\n",
      "Currently :74 %\n",
      "Currently :74 %\n",
      "Currently :75 %\n",
      "Currently :75 %\n",
      "Currently :75 %\n",
      "Currently :75 %\n",
      "Currently :75 %\n",
      "Currently :75 %\n",
      "Currently :75 %\n",
      "Currently :76 %\n",
      "Currently :76 %\n",
      "Currently :76 %\n",
      "Currently :76 %\n",
      "Currently :76 %\n",
      "Currently :76 %\n",
      "Currently :76 %\n",
      "Currently :77 %\n",
      "Currently :77 %\n",
      "Currently :77 %\n",
      "Currently :77 %\n",
      "Currently :77 %\n",
      "Currently :77 %\n",
      "Currently :78 %\n",
      "Currently :78 %\n",
      "Currently :78 %\n",
      "Currently :78 %\n",
      "Currently :78 %\n",
      "Currently :78 %\n",
      "Currently :78 %\n",
      "Currently :79 %\n",
      "Currently :79 %\n",
      "Currently :79 %\n",
      "Currently :79 %\n",
      "Currently :79 %\n",
      "Currently :79 %\n",
      "Currently :79 %\n",
      "Currently :80 %\n",
      "Currently :80 %\n",
      "Currently :80 %\n",
      "Currently :80 %\n",
      "Currently :80 %\n",
      "Currently :80 %\n",
      "Currently :80 %\n",
      "Currently :81 %\n",
      "Currently :81 %\n",
      "Currently :81 %\n",
      "Currently :81 %\n",
      "Currently :81 %\n",
      "Currently :82 %\n",
      "Currently :82 %\n",
      "Currently :82 %\n",
      "Currently :82 %\n",
      "Currently :83 %\n",
      "Currently :83 %\n",
      "Currently :83 %\n",
      "Currently :83 %\n",
      "Currently :83 %\n",
      "Currently :83 %\n",
      "Currently :83 %\n",
      "Currently :84 %\n",
      "Currently :84 %\n",
      "Currently :84 %\n",
      "Currently :84 %\n",
      "Currently :84 %\n",
      "Currently :84 %\n",
      "Currently :84 %\n",
      "Currently :84 %\n",
      "Currently :84 %\n",
      "Currently :84 %\n",
      "Currently :85 %\n",
      "Currently :85 %\n",
      "Currently :85 %\n",
      "Currently :85 %\n",
      "Currently :85 %\n",
      "Currently :85 %\n",
      "Currently :85 %\n",
      "Currently :85 %\n",
      "Currently :86 %\n",
      "Currently :86 %\n",
      "Currently :86 %\n",
      "Currently :86 %\n",
      "Currently :86 %\n",
      "Currently :86 %\n",
      "Currently :86 %\n",
      "Currently :86 %\n",
      "Currently :86 %\n",
      "Currently :86 %\n",
      "Currently :87 %\n",
      "Currently :87 %\n",
      "Currently :87 %\n",
      "Currently :87 %\n",
      "Currently :87 %\n",
      "Currently :87 %\n",
      "Currently :88 %\n",
      "Currently :88 %\n",
      "Currently :88 %\n",
      "Currently :88 %\n",
      "Currently :88 %\n",
      "Currently :88 %\n",
      "Currently :89 %\n",
      "Currently :89 %\n",
      "Currently :89 %\n",
      "Currently :89 %\n",
      "Currently :89 %\n",
      "Currently :89 %\n",
      "Currently :89 %\n",
      "Currently :90 %\n",
      "Currently :90 %\n",
      "Currently :90 %\n",
      "Currently :90 %\n",
      "Currently :90 %\n",
      "Currently :90 %\n",
      "Currently :91 %\n",
      "Currently :91 %\n",
      "Currently :91 %\n",
      "Currently :91 %\n",
      "Currently :92 %\n",
      "Currently :92 %\n",
      "Currently :92 %\n",
      "Currently :92 %\n",
      "Currently :92 %\n",
      "Currently :92 %\n",
      "Currently :93 %\n",
      "Currently :93 %\n",
      "Currently :93 %\n",
      "Currently :93 %\n",
      "Currently :93 %\n",
      "Currently :93 %\n",
      "Currently :93 %\n",
      "Currently :93 %\n",
      "Currently :94 %\n",
      "Currently :94 %\n",
      "Currently :94 %\n",
      "Currently :94 %\n",
      "Currently :94 %\n",
      "Currently :94 %\n",
      "Currently :94 %\n",
      "Currently :94 %\n",
      "Currently :95 %\n",
      "Currently :95 %\n",
      "Currently :95 %\n",
      "Currently :95 %\n",
      "Currently :95 %\n",
      "Currently :95 %\n",
      "Currently :95 %\n",
      "Currently :95 %\n",
      "Currently :95 %\n",
      "Currently :95 %\n",
      "Currently :95 %\n",
      "Currently :95 %\n",
      "Currently :95 %\n",
      "Currently :96 %\n",
      "Currently :96 %\n",
      "Currently :96 %\n",
      "Currently :96 %\n",
      "Currently :96 %\n",
      "Currently :96 %\n",
      "Currently :96 %\n",
      "Currently :96 %\n",
      "Currently :97 %\n",
      "Currently :97 %\n",
      "Currently :97 %\n",
      "Currently :97 %\n",
      "Currently :97 %\n",
      "Currently :97 %\n",
      "Currently :97 %\n",
      "Currently :97 %\n",
      "Currently :97 %\n",
      "Currently :98 %\n",
      "Currently :98 %\n",
      "Currently :98 %\n",
      "Currently :98 %\n",
      "Currently :98 %\n",
      "Currently :98 %\n",
      "Currently :98 %\n",
      "Currently :98 %\n",
      "Currently :99 %\n",
      "Currently :99 %\n",
      "Currently :99 %\n",
      "Currently :99 %\n",
      "Currently :99 %\n",
      "Currently :99 %\n",
      "Currently :99 %\n",
      "Currently :100 %\n",
      "Mean: [0.42501965 0.04450851 0.01185214]\n",
      "Standard Deviation: [0.21046326 0.10559631 0.05186318]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Define a function to calculate mean and standard deviation\n",
    "def calculate_mean_std(dataset_dir):\n",
    "    mean = [0., 0., 0.]\n",
    "    std = [0., 0., 0.]\n",
    "    num_images = 0\n",
    "\n",
    "    # Recursively traverse through each folder in the dataset directory\n",
    "    for root, dirs, files in os.walk(dataset_dir):\n",
    "        for filename in files:\n",
    "            if filename.endswith(('.JPEG')):\n",
    "                # Load the image\n",
    "                img = Image.open(os.path.join(root, filename))\n",
    "                img = np.array(img) / 255.  # Convert pixel values to range [0, 1]\n",
    "\n",
    "                # Calculate mean and standard deviation\n",
    "                mean += np.mean(img, axis=(0, 1))\n",
    "                std += np.std(img, axis=(0, 1))\n",
    "\n",
    "                num_images += 1\n",
    "        print(f\"Currently :{int(num_images/28764*100)} %\")\n",
    "    mean /= num_images\n",
    "    std /= num_images\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "# Example usage\n",
    "dataset_dir = './Data/VID/TRAIN/'\n",
    "mean, std = calculate_mean_std(dataset_dir)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Standard Deviation:\", std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results  \n",
    "\n",
    "Mean: [0.42501965 0.04450851 0.01185214]  \n",
    "Standard Deviation: [0.21046326 0.10559631 0.05186318]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
